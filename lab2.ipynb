{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled82.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8AQrWILYfboyQ4WvlTqx6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZawWin58/firstproject/blob/master/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMDwwHY2j5vc"
      },
      "source": [
        "\n",
        "import random\n",
        "import string\n",
        "import os\n",
        "import collections\n",
        "import multiprocessing as mp\n",
        "from functools import reduce"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7_lIAxvj-8L"
      },
      "source": [
        "\n",
        "def create_file(file_name, file_size):\n",
        "  str_arr = []\n",
        "  if not os.path.isfile(file_name):\n",
        "    open(file_name, \"w\").close()\n",
        "  while os.path.getsize(file_name) / (1024 * 1024 * file_size) < 1:\n",
        "    for i in range(1024):\n",
        "      str_arr.append(''.join(random.choice(string.ascii_letters) for j in range(random.randint(32, 62))) + '\\n')\n",
        "    chunk_of_strs = ''.join(str_arr)\n",
        "    str_arr[:] = []\n",
        "\n",
        "    with open(file_name, 'a+', encoding='utf-8') as file:\n",
        "      file.write(chunk_of_strs)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tllGgWdikGKZ"
      },
      "source": [
        "def mapper(chunk_start, chunk_size, file_name):\n",
        "    with open(file_name) as file:\n",
        "        file.seek(chunk_start)\n",
        "        file_content = file.read(chunk_size).splitlines()\n",
        "        counter = collections.Counter(file_content)\n",
        "        return counter\n",
        "\n",
        "\n",
        "def reducer(counter_1, counter_2):\n",
        "    return counter_1 + counter_2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwNhOMDckPEW"
      },
      "source": [
        "\n",
        "def split_into_chunks(file_name, chunk_size=1024 ** 2):\n",
        "    end_of_file = os.path.getsize(file_name)\n",
        "    with open(file_name, 'rb') as file:\n",
        "        chunk_end = file.tell()\n",
        "        while True:\n",
        "            chunk_start = chunk_end\n",
        "            file.seek(chunk_size, 1)\n",
        "            file.readline()\n",
        "            chunk_end = file.tell()\n",
        "\n",
        "            yield chunk_start, chunk_end - chunk_start\n",
        "\n",
        "            if chunk_end > end_of_file:\n",
        "                break"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbAIN89VkQ9C",
        "outputId": "56f6bb3f-f299-4c4c-c21c-30531733a07e"
      },
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    FILE = \"input_data.txt\"\n",
        "    create_file(FILE, 4)\n",
        "    workers_pool = mp.Pool(8)\n",
        "\n",
        "    task_queue = []\n",
        "\n",
        "    for chunk_start, chunk_size in split_into_chunks(FILE):\n",
        "        task_queue.append(workers_pool.apply_async(mapper, (chunk_start, chunk_size, FILE)))\n",
        "    result = []\n",
        "    for t in task_queue:\n",
        "        result.append(t.get())\n",
        "    workers_pool.close()\n",
        "    common_counter = reduce(reducer, result)\n",
        "    result = sorted(common_counter.items(), key=lambda pair: pair[1], reverse=True)\n",
        "\n",
        "    print(common_counter.most_common(10))\n",
        "    print(result[:10])\n",
        "    print(max(result,key=lambda item:item[1]))\n",
        "    print(min(result,key=lambda item:item[1]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('zmuUbVBjDJYCsJRFxLDvceSdRAiwNopeA', 1), ('FbYwkChUeDwAKVQbmDDzhYXSFoBRJlbEiOtBiRnYKILqIRnAzWEiZjrF', 1), ('oNdVDVNhmasbXObvJnZsXWkrLRBZQanpJ', 1), ('CNEzBsbPGLhTAhRGSwWbbsjFgeerlmmcFusboKLRRBHxqeUeceFhMWLG', 1), ('rNNuXwDdxzjcAFZOBpFUprVcOTblSqYaPrNkWRyDFQDVyTCiJZPLY', 1), ('iCCUFhijsrJQazmsiPRffRGQqditfBknIdhndtEIQZWRTuLO', 1), ('zlDPgXCWErJRfvVSWThQdTWgWfuWUfVslSIBwXhoRafWx', 1), ('hSCYZIxwMStCUanEkRmgOaMzpXGVqisaGbsTJxkrTNZlNhqtDRTlZPohRlJoKL', 1), ('RQVawKGtijkAomdpKwiSYqoOBTHFfRtIObBzOSQlSZIysaGivvnUUzSk', 1), ('dVYuNijUoByfjyqvZKdaqoEkZDvmMOwtvVOefPZcmUErACALigkzyc', 1)]\n",
            "[('zmuUbVBjDJYCsJRFxLDvceSdRAiwNopeA', 1), ('FbYwkChUeDwAKVQbmDDzhYXSFoBRJlbEiOtBiRnYKILqIRnAzWEiZjrF', 1), ('oNdVDVNhmasbXObvJnZsXWkrLRBZQanpJ', 1), ('CNEzBsbPGLhTAhRGSwWbbsjFgeerlmmcFusboKLRRBHxqeUeceFhMWLG', 1), ('rNNuXwDdxzjcAFZOBpFUprVcOTblSqYaPrNkWRyDFQDVyTCiJZPLY', 1), ('iCCUFhijsrJQazmsiPRffRGQqditfBknIdhndtEIQZWRTuLO', 1), ('zlDPgXCWErJRfvVSWThQdTWgWfuWUfVslSIBwXhoRafWx', 1), ('hSCYZIxwMStCUanEkRmgOaMzpXGVqisaGbsTJxkrTNZlNhqtDRTlZPohRlJoKL', 1), ('RQVawKGtijkAomdpKwiSYqoOBTHFfRtIObBzOSQlSZIysaGivvnUUzSk', 1), ('dVYuNijUoByfjyqvZKdaqoEkZDvmMOwtvVOefPZcmUErACALigkzyc', 1)]\n",
            "('zmuUbVBjDJYCsJRFxLDvceSdRAiwNopeA', 1)\n",
            "('zmuUbVBjDJYCsJRFxLDvceSdRAiwNopeA', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}